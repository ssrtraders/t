from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# Create SparkSession
spark = SparkSession.builder \
    .appName("DataFrameUpdate") \
    .getOrCreate()

# Example input DataFrames with additional records
ref_df = spark.createDataFrame([
    (1, "cis1", "entity1", "model1", "v1", "seg1", "grade1", 0.2, "Y", "Country1", "2023-01-01"),
    (2, "cis2", "entity2", "model2", "v2", "seg2", "grade2", 0.3, "N", "Country2", "2023-01-02"),
    (3, "cis3", "entity3", "model3", "v3", "seg3", "grade3", 0.4, "Y", "Country3", "2023-01-03")
], ["sl_no", "cis_code", "entity_name", "model_name", "model_version", "segment", 
    "definitive_grade", "definitive_pd", "cascade_flag", "country_of_operations", "last_grading_date"])

main_data_df = spark.createDataFrame([
    ("01-07-2023", "cp4", "postcrm4", "precrm4", "col1", "col2", "col3"),
    ("01-07-2023", "cp5", "postcrm5", "precrm5", "col1", "col2", "col3"),
    ("01-07-2023", "cis1", "postcrm6", "precrm6", "col1", "col2", "col3"),
    ("01-07-2023", "cis2", "postcrm7", "precrm7", "col1", "col2", "col3"),
    ("01-07-2023", "cp6", "postcrm8", "precrm8", "col1", "col2", "col3"),
    ("01-07-2023", "cis3", "postcrm9", "precrm9", "col1", "col2", "col3")
], ["day_rk", "counterparty_id", "pd_score_postcrm", "pd_score_precrm", "col1", "col2", "col3"])

# Step 1: Print no of records in main_data_df
print("Step 1:")
print("Number of records in main_data_df:", main_data_df.count())

# Step 2: Update main_data_df
# a. Update pd_score_postcrm with ref_df.definitive_pd where ref_df.cis_code = main_data_df.counterparty_id
# b. Update pd_score_precrm with ref_df.definitive_pd where ref_df.cis_code = main_data_df.counterparty_id

updated_main_data_df = main_data_df.join(ref_df, main_data_df["counterparty_id"] == ref_df["cis_code"], "left") \
    .withColumn("pd_score_postcrm", col("definitive_pd")) \
    .withColumn("pd_score_precrm", col("definitive_pd")) \
    .fillna({'pd_score_postcrm': main_data_df['pd_score_postcrm'], 'pd_score_precrm': main_data_df['pd_score_precrm']}) \
    .drop("definitive_pd", "cis_code") \
    .select(main_data_df.columns)

# Step 3: Print no of records in updated_main_data_df
print("\nStep 3:")
print("Number of records in updated_main_data_df:", updated_main_data_df.count())

# Step 4: Print only updated records in main_data_df
print("\nStep 4:")
print("Updated records in main_data_df:")
updated_main_data_df.show(truncate=False)

# Stop SparkSession
spark.stop()
